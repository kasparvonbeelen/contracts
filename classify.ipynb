{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasparbeelen/anaconda3/envs/tou/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from tools.utils import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x29ce0bf80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the spacy model and pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.disable_pipes(\"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\")\n",
    "nlp.add_pipe('sentencizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = Path('processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105245 105245\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.loadtxt(processed_data_dir / 'embedding.tsv')\n",
    "metadata = pd.read_csv(processed_data_dir / 'metadata.tsv',sep='\\t')\n",
    "print(len(embeddings), len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_type = 'arbitration' #'arbitration' | 'opt-out' | 'class_waver' | 'anti-scraping'\n",
    "examples_df = pd.read_excel(f'annotations/{clause_type}_clauses.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_df['processed_text'] = examples_df['Examples'].apply(lambda x: 'clustering: ' + replace_named_entities(nlp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     clustering: please read the following arbitrat...\n",
       "1     clustering: [mask] [mask] [mask] applies to an...\n",
       "2     clustering: in the unlikely event that [mask] ...\n",
       "3     clustering: at the company ’s or your election...\n",
       "4     clustering: you and [mask] agree that [mask] [...\n",
       "5     clustering: any controversy or claim arising o...\n",
       "6     clustering: you and [mask] each agree that any...\n",
       "7     clustering: any dispute relating in any way to...\n",
       "8     clustering: you and company agree that , [mask...\n",
       "9     clustering: except as set forth in the paragra...\n",
       "10    clustering: you and [mask] agree to resolve an...\n",
       "11    clustering: you agree that any dispute between...\n",
       "12    clustering: you and [mask] agree to resolve an...\n",
       "13    clustering: either [mask] or you may demand th...\n",
       "14    clustering: by agreeing to this agreement , yo...\n",
       "15    clustering: you agree that all disputes betwee...\n",
       "16    clustering: except as provided below , you and...\n",
       "17    clustering: you agree that disputes between yo...\n",
       "18    clustering: any disputes shall be resolved by ...\n",
       "19    clustering: for any claim ( excluding claims f...\n",
       "20    clustering: any dispute , claim , or controver...\n",
       "21    clustering: the exclusive means of resolving a...\n",
       "22    clustering: the exclusive means of resolving a...\n",
       "23    clustering: any dispute or claim relating in a...\n",
       "24    clustering: you agree to submit any claim to [...\n",
       "25    clustering: the parties agree that any and all...\n",
       "26    clustering: you and [mask] are instead electin...\n",
       "27    clustering: after the informal dispute resolut...\n",
       "28    clustering: all claims arising out of or relat...\n",
       "29    clustering: you and [mask] agree to resolve an...\n",
       "30    clustering: any controversy or claim arising o...\n",
       "31    clustering: you and paypal each agree that any...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_df['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasparbeelen/anaconda3/envs/tou/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# next line is to check if MPS is available\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "# comment next line if you are want to run code on a GPU\n",
    "#device = 'cuda' if torch.cuda.is_available() else device\n",
    "\n",
    "# load the nomic embed model\n",
    "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True) # trust_remote_code is needed to use the encode method\n",
    "# send the model to the device\n",
    "#model.to(device)\n",
    "#print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embeddings = model.encode(examples_df['processed_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_embedding = target_embeddings.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(embeddings, [average_embedding])\n",
    "top_n_position = np.argpartition(similarity_scores.reshape(-1), -500)[-500:][::-1]\n",
    "out_csv = pd.DataFrame(metadata.iloc[top_n_position].sentence.unique())\n",
    "out_csv.columns = ['sentence']\n",
    "out_csv['label'] = 0\n",
    "#out_csv['similarity'] = similarity_scores[top_n_position]\n",
    "out_csv.to_csv(f'annotations/{clause_type}_most_similar_to_average.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = cosine_similarity(embeddings, target_embeddings)\n",
    "similarity_scores = similarity_scores.max(axis=1)\n",
    "top_n_position = np.argpartition(similarity_scores, -500)[-500:][::-1]\n",
    "out_csv = pd.DataFrame(metadata.iloc[top_n_position].sentence.unique())\n",
    "out_csv.columns = ['sentence']\n",
    "out_csv['label'] = 0\n",
    "#out_csv['similarity'] = similarity_scores[top_n_position]\n",
    "out_csv.to_csv(f'annotations/{clause_type}_most_similar_to_individual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate selected examples with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n",
      "(184, 2)\n"
     ]
    }
   ],
   "source": [
    "# prepare examples for annotation\n",
    "df1 = pd.read_csv(f'annotations/{clause_type}_most_similar_to_individual.csv', index_col=0)\n",
    "df2 = pd.read_csv(f'annotations/{clause_type}_most_similar_to_average.csv', index_col=0)\n",
    "print(len(df1) + len(df2))\n",
    "df = pd.concat([df1, df2], axis=0).drop_duplicates(subset='sentence')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 Below are ten examples of arbitration clauses.\n",
      "\n",
      "All claims arising out of or relating to these Terms (including their formation, performance and breach), the parties’ relationship with each other, and/or your use of the Services (including the Site, the App, and any wagering transactions) shall be finally settled by binding arbitration\n",
      "BY AGREEING TO THIS AGREEMENT, YOU AND GRINDR HEREBY IRREVOCABLY WAIVE ANY CONSTITUTIONAL AND STATUTORY RIGHTS TO SUE IN COURT AND HAVE A TRIAL IN FRONT OF A JUDGE OR A JURY (OTHER THAN SMALL CLAIMS COURT AS PROVIDED ABOVE. You and Grindr are instead electing that all Disputes shall be resolved by arbitration under this arbitration provision.\n",
      "This Arbitration Agreement applies to any disputes or claims of any kind whatsoever (whether based in contract, tort, statute, regulation, ordinance, fraud, misrepresentation or any other legal or equitable theory) between you and the Bumble Group arising out of or relating to the Terms, prior versions of the Terms, your use of our App, or any other aspect of your relationship with Bumble, including claims or disputes arising (but not actually filed in arbitration) before the effective date of these Terms. It requires that, and by entering into these Terms you and Bumble Group agree, that such disputes or claims will be resolved by binding arbitration, rather than in court.\n",
      "Any Disputes shall be resolved by final and binding arbitration under the rules and auspices of the American Arbitration Association.\n",
      "The exclusive means of resolving any dispute or claim arising out of or relating to this Agreement (including any alleged breach thereof), the Service, or the Website shall be BINDING ARBITRATION administered by the American Arbitration Association under the Consumer Arbitration Rules. In doing so, YOU GIVE UP YOUR RIGHT TO GO TO COURT to assert or defend any claims between you and the Company (except for matters that may be taken to small-claims court).\n",
      "The exclusive means of resolving any dispute or claim arising out of or relating to this Agreement (including any alleged breach thereof) or our Services shall be BINDING ARBITRATION.\n",
      "You and Fitbit agree to resolve any Disputes through final and binding arbitration, except as set forth under Exceptions to Agreement to Arbitrate below.\n",
      "Any dispute relating in any way to the Web site and/or the Service (including your visit to or use of the Web site and/or the Service) shall be submitted to confidential arbitration\n",
      "Either Grindr or you may demand that any dispute or claim between Grindr and you about or involving the Grindr Services must be settled by arbitration utilizing the dispute resolution procedures of the American Arbitration Association\n",
      "The parties agree that any and all disputes, claims or controversies arising out of or relating to this Agreement that are not resolved by their mutual agreement by negotiation or mediation shall be submitted to final and binding arbitration before JAMS, or its successor, pursuant to the United States Arbitration Act.\n",
      "\n",
      " Is the following sentence a arbitration clause? Please select only yes or no.\n",
      " you and [mask] [mask] are instead electing to have claims and disputes resolved by arbitration .\n"
     ]
    }
   ],
   "source": [
    "# prepare prompts for annotation\n",
    "sentences = df.sentence.to_list()\n",
    "prompts =[\"\"\"Below are ten examples of {0} clauses.\\n\\n{1}\\n\\n Is the following sentence a {0} clause? Please select only yes or no.\n",
    " {2}\"\"\".format(\n",
    "     clause_type,examples_df['Examples'].sample(10).str.cat(sep='\\n'),s)  for s in sentences]\n",
    "print(len(prompts),prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Below are ten examples of arbitration clauses.\n",
      "\n",
      "Except as set forth in the paragraph below, you agree that all claims and disputes between you and Facebook that arise out of or relate in any way to the Terms or your use of the Facebook Service will be resolved either by (a) binding arbitration by a single arbitrator in Santa Clara County, California or (b) binding non-appearance based arbitration conducted by telephone, online or based solely on written submission. \n",
      "For any claim (excluding claims for injunctive or other equitable relief) where the total amount of the award sought is less than $10,000, the party requesting relief may elect to resolve the dispute in a cost effective manner through binding non-appearance-based arbitration\n",
      "Either Grindr or you may demand that any dispute or claim between Grindr and you about or involving the Grindr Services must be settled by arbitration utilizing the dispute resolution procedures of the American Arbitration Association\n",
      "Any controversy or claim arising out of or relating to this Agreement shall be settled by binding arbitration in accordance with the commercial arbitration rules of the American Arbitration Association. Any such controversy or claim shall be arbitrated on an individual basis, and shall not be consolidated in any arbitration with any claim or controversy of any other party. The arbitrary shall be conducted in San Jose, California, and judgment on the arbitration award may be entered into any court having jurisdiction thereof. Either you or eBay may seek any interim or preliminary relief from a court of competent jurisdiction in San Jose, California necessary to protect the rights or property of you or eBay pending the completion of arbitration.\n",
      "In the unlikely event that Canva has not been able to resolve a dispute it has with you after attempting to do so informally, we each agree to resolve any claim, dispute, or controversy (excluding any Canva claims for injunctive or other equitable relief) arising out of or in connection with or relating to this Agreement, or the breach or alleged breach thereof (collectively, “Claims”), by binding arbitration by the American Arbitration Association (“AAA”) under the Commercial Arbitration Rules and Supplementary Procedures for Consumer Related Disputes then in effect for the AAA, except as provided herein.\n",
      "You and eBay each agree that any and all disputes or claims that have arisen, or may arise, between you and eBay (or any related third parties) that relate in any way to or arise out of this or previous versions of the User Agreement, your use of or access to our Services, the actions of eBay or its agents, or any products or services sold, offered, or purchased through our Services shall be resolved exclusively through final and binding arbitration, rather than in court, subject to any exemptions listed in this section.\n",
      "You and Fitbit agree to resolve any Disputes through final and binding arbitration, except as set forth under Exceptions to Agreement to Arbitrate below.\n",
      "Please read the following arbitration agreement in this Section (“Arbitration Agreement”) carefully. Unless you opt out in the manner described in subsection 7 below, this agreement requires you to arbitrate disputes with Bumble Group and limits the manner in which you seek relief from us.\n",
      "When Does This Arbitration Agreement Apply? This Arbitration Agreement applies to any dispute or claim relating to your use of our App or any other aspect of your relationship with Bumble Group. It requires that, and by entering into these Terms you agree, that such claims will be resolved by binding arbitration, rather than in court.\n",
      "All claims arising out of or relating to these Terms (including their formation, performance and breach), the parties’ relationship with each other, and/or your use of the Services (including the Site, the App, and any wagering transactions) shall be finally settled by binding arbitration\n",
      "You agree that any dispute between you and Fitbit arising out of or relating to these Terms of Service, the Fitbit Service, or any other Fitbit products or services will be governed by the arbitration procedure outlined below.\n",
      "\n",
      "Generate a new sentence similar but not identical to these examples and has the same function as arbitration clause.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "sentences = df.sentence.to_list()\n",
    "syntethic_prompts =[\"\"\"Below are ten examples of {0} clauses.\\n\\n{1}\\n\\nGenerate a new sentence similar but not identical to these examples and has the same function as {0} clause.\n",
    " \"\"\".format(\n",
    "     clause_type,examples_df['Examples'].sample(10).str.cat(sep='\\n'))  for _ in range(100)]\n",
    "print(len(syntethic_prompts),syntethic_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API credentials\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def generate_response(prompt,model='gpt-4o-mini', max_tokens=100,temperature=.0):\n",
    "    # Generate a response using OpenAI ChatGPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        timeout=10\n",
    "    )\n",
    "\n",
    "    # Extract the generated response from the API response\n",
    "    #generated_response = response.choices[0].text.strip()\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.43.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [(sentences[i],generate_response(p,model='gpt-4o',max_tokens=2)) for i, p in tqdm(enumerate(prompts))]\n",
    "responses_df = pd.DataFrame(responses, columns=['text','response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df['synthetic'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.value_counts('response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.response.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntethic_data = [generate_response(p,max_tokens=200,temperature=.3) for i, p in tqdm(enumerate(syntethic_prompts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntethic_data_df = pd.DataFrame(syntethic_data, columns=['text'])\n",
    "syntethic_data_df['text'] = syntethic_data_df['text'].str.lower()\n",
    "syntethic_data_df['labels'] = 1\n",
    "syntethic_data_df['synthetic'] = 1\n",
    "syntethic_data_df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df.replace({'response': {'Yes.': 1,'Yes': 1, 'No': 0,'No.': 0}}, inplace=True)\n",
    "responses_df.rename(columns={'response': 'labels'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_gpt = pd.concat([responses_df, syntethic_data_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_gpt.to_csv(f'annotations/{clause_type}_annotations_gpt4.csv')\n",
    "annotations_gpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotations and train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_scheduler\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_data_dir = Path('processed_data')\n",
    "metadata = pd.read_csv(processed_data_dir / 'metadata.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "annotator = '_gpt4'\n",
    "df_annotations = pd.read_csv(f'annotations/{clause_type}_annotations{annotator}.csv', index_col=0) \n",
    "df_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.value_counts('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = metadata.sample(n=200).reset_index(drop=True)\n",
    "sents = df_sample.sentence.to_list()\n",
    "sents = [s for s in sents if s not in df_annotations.text.to_list()]\n",
    "df_sample = pd.DataFrame(sents, columns=['text'])\n",
    "df_sample['labels'] = 0\n",
    "df_sample.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_annotations[['text','labels']], df_sample[['text','labels']] ], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(data)\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.2)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "model.to('mps')\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-6, weight_decay=0.2)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)\n",
    "\n",
    "\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    print(metric.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"./{clause_type}_model\")\n",
    "tokenizer.save_pretrained(f\"./{clause_type}_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply classifier to all examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f'{clause_type}_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{clause_type}_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "metadata['logits'] = metadata.progress_apply(lambda x: \n",
    "                    softmax(model(**tokenizer(x.sentence, return_tensors='pt', truncation=True)).logits.detach(), dim=1), \n",
    "                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['logits'].iloc[0][0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['prob_1'] = metadata['logits'].apply(lambda x: x[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['prob_1'].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.sort_values('prob_1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deduplicated = metadata.drop_duplicates(subset=['sentence'])\n",
    "df_deduplicated['annotated'] = df_deduplicated.sentence.isin(df_annotations.text)\n",
    "int_labels = [((0.95,1.0),'confident_positive'),( (0.80,.95), 'sure_positive'),((0.60,.80), 'leaning_positive'),\n",
    "                   ((0.50,.60), 'borderline_positive'),((0.40,.50), 'borderline_negative'),\n",
    "                   ((0.20,.40), 'leaning_negative'),((0.05,.20), 'sure_negative'),((0.0,.05), 'confident_negative')]\n",
    "for interval, label in int_labels:\n",
    "\n",
    "\n",
    "    df_deduplicated.loc[df_deduplicated.prob_1.between(*interval),'category']  = label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_deduplicated[df_deduplicated.category == label].sample(10)\n",
    "    for _ , label in int_labels], axis=0)[['sentence','category']].to_csv(f'annotations/{clause_type}_automatic_annotations_by_category.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[metadata.prob_1 > .5].to_csv(f'annotations/{clause_type}_inference.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tou",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
